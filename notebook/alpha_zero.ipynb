{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdf0945-fd71-47db-b638-3ad3269a653c",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "This is a proof of concept on how AlphaZero can be implemented on top of TorchRL. \n",
    "\n",
    "We will apply this technique on CliffWalking-v0 environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd8cc51-a251-4258-b834-76dd62ea60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tensordict.nn import TensorDictModule\n",
    "\n",
    "from torchrl.modules import QValueActor\n",
    "\n",
    "from torchrl.envs import GymEnv, TransformedEnv, Compose, DTypeCastTransform, StepCounter\n",
    "\n",
    "from torchrl.objectives import DQNLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb754c-1cd4-4254-91fa-ecb95724ee28",
   "metadata": {},
   "source": [
    "# QValue Network\n",
    "\n",
    "Lets first create a QValue network. QValue networks provide an initial value for each action when we explore a node for the first time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2116d9-f8ed-4e5a-9df5-6ee2992baee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majid/miniconda3/envs/torchrl_mcts/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/majid/miniconda3/envs/torchrl_mcts/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        action_value: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([48]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        step_count: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_q_value(num_observation, num_action, action_space):\n",
    "    net = torch.nn.Linear(num_observation, num_action)\n",
    "    qvalue_module = QValueActor(net, in_keys=[\"observation\"], action_space=action_space)\n",
    "    return qvalue_module\n",
    "\n",
    "\n",
    "env = TransformedEnv(\n",
    "    GymEnv(\"CliffWalking-v0\"),\n",
    "    Compose(\n",
    "        DTypeCastTransform(dtype_in=torch.long, dtype_out=torch.float32, in_keys=[\"observation\"]), \n",
    "        StepCounter(),\n",
    "    )\n",
    ")\n",
    "qvalue_module = make_q_value(env.observation_spec[\"observation\"].shape[-1], env.action_spec.shape[-1], env.action_spec)\n",
    "qvalue_module(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ffd66c-5b71-4a9e-b506-4235e07ce5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majid/miniconda3/envs/torchrl_mcts/lib/python3.10/site-packages/torchrl/objectives/dqn.py:176: UserWarning: You did not provide a delay_value argument for <class 'torchrl.objectives.dqn.DQNLoss'>. Currently (v0.3) the default for delay_value is `False` but as of v0.4 it will be `True`. Make sure to adapt your code depending on your preferred configuration. To remove this warning, indicate the value of delay_value in your script.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loss_module = DQNLoss(qvalue_module, action_space=env.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857b0b9a-5e08-4b2d-84d2-5c10191a2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts.tensordict_map import TensorDictMap\n",
    "from mcts.mcts_policy import SimulatedSearchPolicy, MctsPolicy, UpdateTreeStrategy, AlphaZeroExpansionStrategy, PucbSelectionPolicy\n",
    "\n",
    "tree = TensorDictMap([\"observation\", \"step_count\"])\n",
    "\n",
    "policy = SimulatedSearchPolicy(\n",
    "    policy=MctsPolicy(\n",
    "        expansion_strategy=AlphaZeroExpansionStrategy(value_module=qvalue_module, tree=tree),\n",
    "        selection_strategy=PucbSelectionPolicy(),\n",
    "    ),\n",
    "    tree_updater=UpdateTreeStrategy(tree),\n",
    "    env=env,\n",
    "    num_simulation=100,\n",
    "    max_steps=1000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abfdff8-fb8b-4119-b4f3-be0e253a08b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation: 0\n",
      "\n",
      "q_sa -> [-0.10321956 -0.07089151 -0.08972184 -5.        ]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 0. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [-0.10321956 -0.07089151 -0.08972184 -4.        ]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 0. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [1]\n",
      "q_sa -> [-0.10321956 -0.07089151 -0.08972184 -3.        ]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 0. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [2]\n",
      "q_sa -> [-0.10321956 -0.07089151 -0.08972184 -2.        ]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 0. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [3]\n",
      "q_sa -> [-0.10321956 -0.07089151 -0.08972184 -1.        ]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 0. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [4]\n",
      "simulation: 1\n",
      "\n",
      "q_sa -> [-1.0321956e-01 -5.0000000e+02 -8.9721836e-02 -5.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [-1.0321956e-01 -4.0000000e+02 -8.9721836e-02 -4.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [1]\n",
      "q_sa -> [-1.0321956e-01 -3.0000000e+02 -8.9721836e-02 -3.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [2]\n",
      "q_sa -> [-1.0321956e-01 -2.0000000e+02 -8.9721836e-02 -2.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [3]\n",
      "q_sa -> [-1.0321956e-01 -1.0000000e+02 -8.9721836e-02 -1.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [4]\n",
      "simulation: 2\n",
      "\n",
      "q_sa -> [-1.0321956e-01 -5.0000000e+02 -5.0000000e+00 -5.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 1. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [-1.0321956e-01 -4.0000000e+02 -4.0000000e+00 -4.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 1. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [1]\n",
      "q_sa -> [-1.0321956e-01 -3.0000000e+02 -3.0000000e+00 -3.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 1. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [2]\n",
      "q_sa -> [-1.0321956e-01 -2.0000000e+02 -2.0000000e+00 -2.0000000e+00]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 1. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [3]\n",
      "q_sa -> [  -0.10321956 -100.           -1.           -1.        ]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [0. 1. 1. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [4]\n",
      "simulation: 3\n",
      "\n",
      "q_sa -> [  -5. -500.   -5.   -5.]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [1. 1. 1. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [-0.11799396 -4.         -0.19711387 -0.03945922]\n",
      "p_sa -> [-0.11799396  0.02269601 -0.19711387 -0.03945922]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [1]\n",
      "q_sa -> [-0.01715441 -3.         -0.24038734 -0.01899591]\n",
      "p_sa -> [-0.01715441  0.06112372 -0.24038734 -0.01899591]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [2]\n",
      "q_sa -> [-0.18510342 -2.         -0.2628031  -0.13708326]\n",
      "p_sa -> [-0.18510342  0.038135   -0.2628031  -0.13708326]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [3]\n",
      "q_sa -> [-0.176198   -1.         -0.14386594  0.02299713]\n",
      "p_sa -> [-0.176198    0.06539991 -0.14386594  0.02299713]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [4]\n",
      "simulation: 4\n",
      "\n",
      "q_sa -> [  -5. -500.   -5.   -5.]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [1. 1. 1. 2.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [-0.176198   -4.         -0.14386594  0.02299713]\n",
      "p_sa -> [-0.176198    0.06539991 -0.14386594  0.02299713]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [1]\n",
      "q_sa -> [ 0.01130294 -3.         -0.17671947 -0.04684141]\n",
      "p_sa -> [ 0.01130294  0.04031233 -0.17671947 -0.04684141]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [2]\n",
      "q_sa -> [-2.         -0.07171631 -0.17501752 -0.05919502]\n",
      "p_sa -> [ 0.02510899 -0.07171631 -0.17501752 -0.05919502]\n",
      "n_sa -> [1. 0. 0. 0.]\n",
      "action -> [1 0 0 0]\n",
      "step_count -> [3]\n",
      "q_sa -> [ 0.02427778 -1.          0.01142791 -0.16748273]\n",
      "p_sa -> [ 0.02427778  0.14355783  0.01142791 -0.16748273]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [4]\n",
      "simulation: 5\n",
      "\n",
      "q_sa -> [  -5. -500.   -5.   -5.]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [1. 1. 1. 3.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [ 0.02427778 -4.          0.01142791 -0.16748273]\n",
      "p_sa -> [ 0.02427778  0.14355783  0.01142791 -0.16748273]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [1]\n",
      "q_sa -> [ 0.02143949 -3.         -0.1548728  -0.2207522 ]\n",
      "p_sa -> [ 0.02143949  0.04831386 -0.1548728  -0.2207522 ]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [2]\n",
      "q_sa -> [-0.13566113 -2.         -0.21600634 -0.1614269 ]\n",
      "p_sa -> [-0.13566113 -0.01755035 -0.21600634 -0.1614269 ]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [3]\n",
      "q_sa -> [-0.08921076 -0.05580505 -0.09196037 -1.        ]\n",
      "p_sa -> [-0.08921076 -0.05580505 -0.09196037  0.01413821]\n",
      "n_sa -> [0. 0. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [4]\n",
      "simulation: 6\n",
      "\n",
      "q_sa -> [  -5. -500.   -5.   -5.]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [1. 1. 1. 4.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [ 0.02143949 -4.         -0.1548728  -0.2207522 ]\n",
      "p_sa -> [ 0.02143949  0.04831386 -0.1548728  -0.2207522 ]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [1]\n",
      "q_sa -> [-0.13566113 -3.         -0.21600634 -0.1614269 ]\n",
      "p_sa -> [-0.13566113 -0.01755035 -0.21600634 -0.1614269 ]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [2]\n",
      "q_sa -> [-0.08921076 -0.05580505 -0.09196037 -2.        ]\n",
      "p_sa -> [-0.08921076 -0.05580505 -0.09196037  0.01413821]\n",
      "n_sa -> [0. 0. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [3]\n",
      "q_sa -> [-0.13566113 -1.         -0.21600634 -0.1614269 ]\n",
      "p_sa -> [-0.13566113 -0.01755035 -0.21600634 -0.1614269 ]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [4]\n",
      "simulation: 7\n",
      "\n",
      "q_sa -> [  -5. -500.   -5.   -5.]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [1. 1. 1. 5.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [-0.13566113 -4.         -0.21600634 -0.1614269 ]\n",
      "p_sa -> [-0.13566113 -0.01755035 -0.21600634 -0.1614269 ]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [1]\n",
      "q_sa -> [-0.08921076 -0.05580505 -0.09196037 -3.        ]\n",
      "p_sa -> [-0.08921076 -0.05580505 -0.09196037  0.01413821]\n",
      "n_sa -> [0. 0. 0. 1.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [2]\n",
      "q_sa -> [-2.         -2.         -0.21600634 -0.1614269 ]\n",
      "p_sa -> [-0.13566113 -0.01755035 -0.21600634 -0.1614269 ]\n",
      "n_sa -> [1. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [3]\n",
      "q_sa -> [-0.14481354 -1.         -0.17608441 -0.03911014]\n",
      "p_sa -> [-0.14481354  0.00303459 -0.17608441 -0.03911014]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [4]\n",
      "simulation: 8\n",
      "\n",
      "q_sa -> [  -5. -500.   -5.   -5.]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [1. 1. 1. 6.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [-0.14481354 -4.         -0.17608441 -0.03911014]\n",
      "p_sa -> [-0.14481354  0.00303459 -0.17608441 -0.03911014]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [1]\n",
      "q_sa -> [-0.00680983 -3.          0.00991434 -0.04106338]\n",
      "p_sa -> [-0.00680983  0.07602484  0.00991434 -0.04106338]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [2]\n",
      "q_sa -> [-0.12829386 -2.         -0.03399943 -0.23814815]\n",
      "p_sa -> [-0.12829386  0.07376024 -0.03399943 -0.23814815]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [3]\n",
      "q_sa -> [ 0.03125383 -1.         -0.00749541 -0.05778866]\n",
      "p_sa -> [ 0.03125383  0.04592574 -0.00749541 -0.05778866]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [4]\n",
      "simulation: 9\n",
      "\n",
      "q_sa -> [  -5. -500.   -5.   -5.]\n",
      "p_sa -> [-0.10321956 -0.07089151 -0.08972184 -0.07059182]\n",
      "n_sa -> [1. 1. 1. 7.]\n",
      "action -> [0 0 0 1]\n",
      "step_count -> [0]\n",
      "q_sa -> [ 0.03125383 -4.         -0.00749541 -0.05778866]\n",
      "p_sa -> [ 0.03125383  0.04592574 -0.00749541 -0.05778866]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [1]\n",
      "q_sa -> [-0.0621062  -3.         -0.02187512 -0.20958328]\n",
      "p_sa -> [-0.0621062   0.01664337 -0.02187512 -0.20958328]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [2]\n",
      "q_sa -> [-0.0621062  -2.         -0.02187512 -0.20958328]\n",
      "p_sa -> [-0.0621062   0.01664337 -0.02187512 -0.20958328]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [3]\n",
      "q_sa -> [-0.0621062  -1.         -0.02187512 -0.20958328]\n",
      "p_sa -> [-0.0621062   0.01664337 -0.02187512 -0.20958328]\n",
      "n_sa -> [0. 1. 0. 0.]\n",
      "action -> [0 1 0 0]\n",
      "step_count -> [4]\n"
     ]
    }
   ],
   "source": [
    "res = policy(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba4a4f4-71e8-45d9-833a-cae089d3a467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree._dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2482ddfe-9b1b-4a9e-834b-b0c36c16bfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  -5., -500.,   -5.,   -5.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"q_sa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a877bc8-567a-4f1d-969c-47991b331a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 7.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"n_sa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aea3801-1aee-48af-b8f6-ae2146c60d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  -5.0816, -500.0560,   -5.0709,   -5.0140])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"action_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b62e3c8-ab53-4078-bbe9-b1818c67fa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25222f02-914d-44cd-9c3f-5fab5aec8bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
